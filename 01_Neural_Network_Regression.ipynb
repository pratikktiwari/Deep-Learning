{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Neural Network Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZF5hTZhxyTCFcDOQoSg/B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikktiwari/ML-Learnings/blob/main/01_Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "There are many definitions for a regression problem but in our case, we're going to to simplify it: predicting numerical variables based on some other combination of variables, even shorter... predicting number."
      ],
      "metadata": {
        "id": "Jo5yDLGLPhgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensforFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWnLOMKwQIz5",
        "outputId": "bb1518e2-eb0c-4072-f28e-7ddd5e24e399"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data to view and fit"
      ],
      "metadata": {
        "id": "UuEvUrlAQeAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "3uTbTCFNQwoX",
        "outputId": "5ffbabbc-4544-401d-e22d-e712f39b3d29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f214abdc810>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Relationship\n",
        "\n",
        "y == X + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckFcQ18TRTz0",
        "outputId": "997e866d-e04f-49c4-849e-40e6035f8e3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and output shapes"
      ],
      "metadata": {
        "id": "F-G5QsghRmm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gamcQ4niRtCR",
        "outputId": "62ca2e7f-ae23-4949-c138-53b6157b877f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0jYKXIHSiVU",
        "outputId": "ca3e3630-72a3-4c5f-c1d2-66fff5cab77c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1], y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCVgC1ymSlhU",
        "outputId": "11353374-e6f6-4396-9434-9c002f76827a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RONv4K2zSQ-5",
        "outputId": "bd357599-f4bb-4734-b895-7bc8924afd45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar has no shape\n",
        "X[0].ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8XnSMNNSdLo",
        "outputId": "63c426af-c59e-4ed6-c5e1-6569e3834d1a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut_Bm9FbS5sK",
        "outputId": "7e64031a-f5ec-4cd0-f8b3-156a7af0418a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBOvLcfyS8Sa",
        "outputId": "a6447051-b618-4c71-965e-3afe6bb2b8ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVES0d0wTSu0",
        "outputId": "43112da4-368c-469b-a323-50b01388ad1c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "7AW5wdd-Tiw7",
        "outputId": "076dee7c-231c-4612-d342-6f6bd8bab6f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f214ab22e90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the ***loss function*** (in other words, the function which tells out model how wrong it is) and the ***optimizer*** (tells our model how to improve the patterns it is learning) and ***evaluation metrics*** (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model** - letting the model try to find patterns between X & y (features and labels).\n",
        "\n",
        "![image.png](https://raw.githubusercontent.com/pratikktiwari/ML-Learnings/main/resources/regression-steps.png?token=GHSAT0AAAAAABQ3M2PPCKOGBQU5BDUWWXZUYVURCGA)"
      ],
      "metadata": {
        "id": "j02MadiSTkE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Loss**: How wrong the model's predictions are compared to the truth labels (this should be minimized)\n",
        "* **Optimizer**: How the model should update its internal patterns to better its predictions\n",
        "* **Metrics**: Human interpretable values for how well the model is doing\n",
        "* **Epochs**: How many times the model will go through all of the training examples"
      ],
      "metadata": {
        "id": "-jrRmI2xK5xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [tf.keras.layers.Dense(1, input_shape=[1])] # take 1 neuron, shape of a single feature\n",
        ")\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # Mean absolute error => comparision of predicted vs observed => loss = mean(abs(y_true - y_pred), axis=-1)\n",
        "              optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochasitc gradient descent => tells neural network how it should improve\n",
        "              metrics=[\"mae\"]) \n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, epochs=5) # Look at X and y and figure out pattern. Try 5 times.\n",
        "\n"
      ],
      "metadata": {
        "id": "shdpqzI6UGP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44244f2-2f4d-4189-b80c-ee5bd4e557d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 543ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2146813f90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_1jEJKVCDpC",
        "outputId": "42588571-92bd-4eb1-a839-ed06b8d21533"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a prediction using our trained model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLN1DnQ8D6IJ",
        "outputId": "6dd52224-898d-48d0-9aab-402bfd13eafb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred + 11 # loss = 10.9 ~ 11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrVr4zzSG1MH",
        "outputId": "aa11bf5d-60b0-42e7-8dfc-d5252e4ffa2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.71602]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "We can improve our mode, by altering the steps we took to create a model.\n",
        "1. **Creating a model** - we might add more layers, increase the number of hidden units (also called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "3. **Compiling a model** - we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "4. **Fitting a model** - we might fit a model for more **epochs** (leave it training for longer) or on more data (give more examples to the model to learn from)"
      ],
      "metadata": {
        "id": "bYvf-4rBHPWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model with higher epoch for fitting\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Sequential(\n",
        "  [tf.keras.layers.Dense(1, input_shape=[1])]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"]\n",
        ")\n",
        "model.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj9XW-ZMHeel",
        "outputId": "f3677a08-982b-4306-c8c5-812244b16175"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8869 - mae: 6.8869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2144fc0b10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhWaknOIH7uI",
        "outputId": "ed009175-9c70-44a0-d290-0a9024d9a2a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if model prediction has improved\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tq87-B9N0lQ",
        "outputId": "e5a65130-7674-4cde-a6d9-a27564fd236b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alter layers and check accuracy\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(500, input_shape=[1]), # 500 neurons in the first layer\n",
        "  tf.keras.layers.Dense(20, input_shape=[1]), # 20 neurons in the second layer\n",
        "  tf.keras.layers.Dense(1, input_shape=[1]), # 1 neuron in the last layer\n",
        "])\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "model.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfLDh-a7N29C",
        "outputId": "c680368c-51a8-4fb9-96b7-51e3a1326b94"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 13.3450 - mae: 13.3450\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.4731 - mae: 12.4731\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.5841 - mae: 11.5841\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6527 - mae: 10.6527\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.6513 - mae: 9.6513\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5489 - mae: 8.5489\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3088 - mae: 7.3088\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5944 - mae: 7.5944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1105 - mae: 7.1105\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0675 - mae: 7.0675\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0240 - mae: 7.0240\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.9801 - mae: 6.9801\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9358 - mae: 6.9358\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8910 - mae: 6.8910\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8457 - mae: 6.8457\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7998 - mae: 6.7998\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7533 - mae: 6.7533\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.7061 - mae: 6.7061\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6581 - mae: 6.6581\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6095 - mae: 6.6095\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5824 - mae: 6.5824\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9757 - mae: 6.9757\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7519 - mae: 6.7519\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5743 - mae: 6.5743\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9321 - mae: 6.9321\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3519 - mae: 6.3519\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2995 - mae: 6.2995\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2460 - mae: 6.2460\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1913 - mae: 6.1913\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1354 - mae: 6.1354\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0780 - mae: 6.0780\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0669 - mae: 6.0669\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4926 - mae: 6.4926\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2646 - mae: 6.2646\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0196 - mae: 6.0196\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4752 - mae: 6.4752\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.7751 - mae: 5.7751\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7101 - mae: 5.7101\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6433 - mae: 5.6433\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5840 - mae: 5.5840\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1772 - mae: 6.1772\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8001 - mae: 5.8001\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.6415 - mae: 5.6415\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.1042 - mae: 6.1042\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0805 - mae: 6.0805\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5073 - mae: 5.5073\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5176 - mae: 5.5176\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.8087 - mae: 5.8087\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.9491 - mae: 5.9491\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2190 - mae: 5.2190\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3547 - mae: 5.3547\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5397 - mae: 5.5397\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.7820 - mae: 5.7820\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9300 - mae: 4.9300\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1509 - mae: 5.1509\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2919 - mae: 5.2919\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5775 - mae: 5.5775\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6346 - mae: 4.6346\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9038 - mae: 4.9038\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0600 - mae: 5.0600\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3334 - mae: 5.3334\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3267 - mae: 4.3267\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6102 - mae: 4.6102\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8387 - mae: 4.8387\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0465 - mae: 5.0465\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9994 - mae: 3.9994\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2657 - mae: 4.2657\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6221 - mae: 4.6221\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7131 - mae: 4.7131\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6599 - mae: 3.6599\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1447 - mae: 5.1447\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0581 - mae: 3.0581\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9972 - mae: 2.9972\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0192 - mae: 4.0192\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5621 - mae: 3.5621\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4869 - mae: 4.4869\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5681 - mae: 2.5681\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5133 - mae: 3.5133\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.3551 - mae: 3.3551\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.2801 - mae: 5.2801\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3787 - mae: 2.3787\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7185 - mae: 4.7185\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7505 - mae: 2.7505\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1495 - mae: 4.1495\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3107 - mae: 3.3107\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9797 - mae: 4.9797\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1628 - mae: 3.1628\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9020 - mae: 4.9020\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0237 - mae: 3.0237\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8388 - mae: 4.8388\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0266 - mae: 2.0266\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2788 - mae: 4.2788\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5033 - mae: 2.5033\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2027 - mae: 5.2027\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4015 - mae: 2.4015\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1145 - mae: 5.1145\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3054 - mae: 2.3054\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0333 - mae: 5.0333\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2146 - mae: 2.2146\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9581 - mae: 4.9581\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2142b6f890>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZfPVuKHPaV6",
        "outputId": "d7655aa8-a8da-43eb-b7fd-4892273e679d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])\n",
        "\n",
        "# Previous output [29.739855]\n",
        "# Current output [31.389563]\n",
        "\n",
        "# Current model accuracy is lower than previous as the actual value if 17 + 10 = 27\n",
        "# and 29 is closer to 27 than 31"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ01ajV7PbsP",
        "outputId": "b94d3480-e0f8-4d9f-ed79-cb453c0b5ef4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.389563]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding activation function to the layers\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\", input_shape=[1]), # ReLU - rectified linear unit activation function\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\", input_shape=[1]),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\", input_shape=[1]),\n",
        "  tf.keras.layers.Dense(1, activation=\"relu\", input_shape=[1])\n",
        "])\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(), \n",
        "              loss=tf.keras.losses.mae,\n",
        "              metrics=[\"mae\"]\n",
        ")\n",
        "model.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "CtTN3yxDPeBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c741844e-13d3-4384-da66-e825da5edc0f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 581ms/step - loss: 12.6673 - mae: 12.6673\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.2183 - mae: 12.2183\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.7456 - mae: 11.7456\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.2312 - mae: 11.2312\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6393 - mae: 10.6393\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.9557 - mae: 9.9557\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.1022 - mae: 9.1022\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1573 - mae: 8.1573\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9100 - mae: 6.9100\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.2134 - mae: 5.2134\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0167 - mae: 4.0167\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0122 - mae: 4.0122\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0280 - mae: 4.0280\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9648 - mae: 3.9648\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0424 - mae: 4.0424\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9162 - mae: 3.9162\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0556 - mae: 4.0556\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8646 - mae: 3.8646\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0724 - mae: 4.0724\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8586 - mae: 3.8586\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0287 - mae: 4.0287\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.8753 - mae: 3.8753\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9767 - mae: 3.9767\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8922 - mae: 3.8922\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.9222 - mae: 3.9222\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9098 - mae: 3.9098\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8664 - mae: 3.8664\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9282 - mae: 3.9282\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8097 - mae: 3.8097\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9484 - mae: 3.9484\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7505 - mae: 3.7505\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9689 - mae: 3.9689\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7754 - mae: 3.7754\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.8935 - mae: 3.8935\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8131 - mae: 3.8131\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8325 - mae: 3.8325\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8352 - mae: 3.8352\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7690 - mae: 3.7690\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8595 - mae: 3.8595\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7040 - mae: 3.7040\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8840 - mae: 3.8840\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6950 - mae: 3.6950\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8392 - mae: 3.8392\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7357 - mae: 3.7357\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7769 - mae: 3.7769\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7589 - mae: 3.7589\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7080 - mae: 3.7080\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7859 - mae: 3.7859\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6383 - mae: 3.6383\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8139 - mae: 3.8139\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6178 - mae: 3.6178\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7673 - mae: 3.7673\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6718 - mae: 3.6718\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6955 - mae: 3.6955\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6995 - mae: 3.6995\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6209 - mae: 3.6209\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7291 - mae: 3.7291\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.5462 - mae: 3.5462\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7582 - mae: 3.7582\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5587 - mae: 3.5587\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7088 - mae: 3.7088\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6180 - mae: 3.6180\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5929 - mae: 3.5929\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6489 - mae: 3.6489\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5125 - mae: 3.5125\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6811 - mae: 3.6811\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4882 - mae: 3.4882\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.6433 - mae: 3.6433\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5201 - mae: 3.5201\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5693 - mae: 3.5693\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5833 - mae: 3.5833\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4603 - mae: 3.4603\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6161 - mae: 3.6161\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4264 - mae: 3.4264\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5844 - mae: 3.5844\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4604 - mae: 3.4604\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4968 - mae: 3.4968\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4955 - mae: 3.4955\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4068 - mae: 3.4068\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5324 - mae: 3.5324\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3465 - mae: 3.3465\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.5495 - mae: 3.5495\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.4105 - mae: 3.4105\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4172 - mae: 3.4172\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4461 - mae: 3.4461\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3193 - mae: 3.3193\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4835 - mae: 3.4835\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2988 - mae: 3.2988\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.4289 - mae: 3.4289\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3349 - mae: 3.3349\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3287 - mae: 3.3287\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3746 - mae: 3.3746\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2313 - mae: 3.2313\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4484 - mae: 3.4484\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2606 - mae: 3.2606\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3207 - mae: 3.3207\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.2985 - mae: 3.2985\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2147 - mae: 3.2147\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3373 - mae: 3.3373\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1595 - mae: 3.1595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f213f587c50>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1AU7TVHUtAM",
        "outputId": "c7f2f923-2d57-401e-a8b9-4d2fbe09e638"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.215181]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previous highest accuracy result = [29.739855]\n",
        "# Current accuracy result = [29.215181]\n",
        "\n",
        "# Current is better but just by a small margin"
      ],
      "metadata": {
        "id": "8T927VZUU3k6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the optimizer during compilation\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1, input_shape=[1]) #, activation=\"relu\"\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "model.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_GHLf7dVNMV",
        "outputId": "62e25c61-fd0a-46b9-faeb-b00d1594be30"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 9.0232 - mae: 9.0232\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.0227 - mae: 9.0227\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 9.0223 - mae: 9.0223\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.0218 - mae: 9.0218\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.0214 - mae: 9.0214\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 9.0209 - mae: 9.0209\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 9.0205 - mae: 9.0205\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0200 - mae: 9.0200\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0196 - mae: 9.0196\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0191 - mae: 9.0191\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0187 - mae: 9.0187\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0182 - mae: 9.0182\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0178 - mae: 9.0178\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0173 - mae: 9.0173\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0169 - mae: 9.0169\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0164 - mae: 9.0164\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.0160 - mae: 9.0160\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0155 - mae: 9.0155\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0151 - mae: 9.0151\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0146 - mae: 9.0146\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0142 - mae: 9.0142\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0137 - mae: 9.0137\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0133 - mae: 9.0133\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.0128 - mae: 9.0128\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0124 - mae: 9.0124\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.0119 - mae: 9.0119\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.0115 - mae: 9.0115\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.0110 - mae: 9.0110\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0106 - mae: 9.0106\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0101 - mae: 9.0101\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.0097 - mae: 9.0097\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.0092 - mae: 9.0092\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0088 - mae: 9.0088\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0083 - mae: 9.0083\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.0079 - mae: 9.0079\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0074 - mae: 9.0074\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0070 - mae: 9.0070\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0065 - mae: 9.0065\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0061 - mae: 9.0061\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0056 - mae: 9.0056\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 9.0052 - mae: 9.0052\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 9.0047 - mae: 9.0047\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.0043 - mae: 9.0043\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 9.0038 - mae: 9.0038\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 9.0034 - mae: 9.0034\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.0029 - mae: 9.0029\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0025 - mae: 9.0025\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 9.0020 - mae: 9.0020\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.0016 - mae: 9.0016\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0011 - mae: 9.0011\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.0007 - mae: 9.0007\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0002 - mae: 9.0002\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9998 - mae: 8.9998\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9993 - mae: 8.9993\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9989 - mae: 8.9989\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9984 - mae: 8.9984\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9980 - mae: 8.9980\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9975 - mae: 8.9975\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.9971 - mae: 8.9971\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.9966 - mae: 8.9966\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9962 - mae: 8.9962\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9957 - mae: 8.9957\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9953 - mae: 8.9953\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9948 - mae: 8.9948\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9944 - mae: 8.9944\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.9939 - mae: 8.9939\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9935 - mae: 8.9935\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9930 - mae: 8.9930\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9926 - mae: 8.9926\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.9921 - mae: 8.9921\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9917 - mae: 8.9917\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9912 - mae: 8.9912\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9908 - mae: 8.9908\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9903 - mae: 8.9903\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9899 - mae: 8.9899\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9894 - mae: 8.9894\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.9890 - mae: 8.9890\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.9885 - mae: 8.9885\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9881 - mae: 8.9881\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9876 - mae: 8.9876\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9872 - mae: 8.9872\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9867 - mae: 8.9867\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9863 - mae: 8.9863\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9858 - mae: 8.9858\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9854 - mae: 8.9854\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9849 - mae: 8.9849\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9845 - mae: 8.9845\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9840 - mae: 8.9840\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9836 - mae: 8.9836\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9831 - mae: 8.9831\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.9827 - mae: 8.9827\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9822 - mae: 8.9822\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.9818 - mae: 8.9818\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9813 - mae: 8.9813\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9809 - mae: 8.9809\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9804 - mae: 8.9804\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9800 - mae: 8.9800\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9795 - mae: 8.9795\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9791 - mae: 8.9791\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.9786 - mae: 8.9786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2142c5e290>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KzTrKGdV2De",
        "outputId": "b0ad6c6c-8239-4650-8814-e59b27b514fb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[21.924559]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previous result = 29.215181\n",
        "# Current result = 21.924559\n",
        "\n",
        "# previous_difference = 2.215181\n",
        "# current_difference = 6.924559\n",
        "\n",
        "# Previous model was better"
      ],
      "metadata": {
        "id": "MUhCYTAfV5cS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining all above model optimization techniques\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100, input_shape=[1], activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, input_shape=[1], activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, input_shape=[1], activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, input_shape=[1])\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr=learning rate, by how much should model improve\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "model.fit(X, y, epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRz8XPwRWSKb",
        "outputId": "0ec823fa-f088-4733-f67f-f695f9f060eb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 728ms/step - loss: 13.3846 - mae: 13.3846\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 13.3561 - mae: 13.3561\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.3276 - mae: 13.3276\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.2992 - mae: 13.2992\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.2713 - mae: 13.2713\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.2435 - mae: 13.2435\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.2160 - mae: 13.2160\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.1885 - mae: 13.1885\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.1610 - mae: 13.1610\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.1334 - mae: 13.1334\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.1066 - mae: 13.1066\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.0814 - mae: 13.0814\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 13.0560 - mae: 13.0560\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.0306 - mae: 13.0306\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.0052 - mae: 13.0052\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.9797 - mae: 12.9797\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.9541 - mae: 12.9541\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.9286 - mae: 12.9286\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12.9032 - mae: 12.9032\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.8777 - mae: 12.8777\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.8524 - mae: 12.8524\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.8272 - mae: 12.8272\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.8028 - mae: 12.8028\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.7788 - mae: 12.7788\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.7553 - mae: 12.7553\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.7318 - mae: 12.7318\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.7084 - mae: 12.7084\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 12.6849 - mae: 12.6849\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12.6614 - mae: 12.6614\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 12.6378 - mae: 12.6378\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.6144 - mae: 12.6144\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.5910 - mae: 12.5910\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12.5677 - mae: 12.5677\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.5445 - mae: 12.5445\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.5212 - mae: 12.5212\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.4979 - mae: 12.4979\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.4745 - mae: 12.4745\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12.4510 - mae: 12.4510\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12.4273 - mae: 12.4273\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.4034 - mae: 12.4034\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.3793 - mae: 12.3793\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.3547 - mae: 12.3547\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.3300 - mae: 12.3300\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.3051 - mae: 12.3051\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.2800 - mae: 12.2800\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.2547 - mae: 12.2547\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 12.2292 - mae: 12.2292\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12.2036 - mae: 12.2036\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.1777 - mae: 12.1777\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 12.1517 - mae: 12.1517\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.1255 - mae: 12.1255\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.0990 - mae: 12.0990\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.0725 - mae: 12.0725\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.0458 - mae: 12.0458\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.0189 - mae: 12.0189\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.9919 - mae: 11.9919\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 11.9647 - mae: 11.9647\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 11.9371 - mae: 11.9371\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 11.9093 - mae: 11.9093\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.8814 - mae: 11.8814\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 11.8534 - mae: 11.8534\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 11.8252 - mae: 11.8252\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.7969 - mae: 11.7969\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.7688 - mae: 11.7688\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.7405 - mae: 11.7405\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.7120 - mae: 11.7120\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.6833 - mae: 11.6833\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 11.6543 - mae: 11.6543\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 11.6251 - mae: 11.6251\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 11.5958 - mae: 11.5958\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 11.5662 - mae: 11.5662\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 11.5363 - mae: 11.5363\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.5062 - mae: 11.5062\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.4759 - mae: 11.4759\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.4454 - mae: 11.4454\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.4148 - mae: 11.4148\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.3839 - mae: 11.3839\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.3527 - mae: 11.3527\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.3212 - mae: 11.3212\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.2893 - mae: 11.2893\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.2571 - mae: 11.2571\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.2246 - mae: 11.2246\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.1917 - mae: 11.1917\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.1585 - mae: 11.1585\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.1250 - mae: 11.1250\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.0910 - mae: 11.0910\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.0567 - mae: 11.0567\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.0219 - mae: 11.0219\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.9977 - mae: 10.9977\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.9753 - mae: 10.9753\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.9526 - mae: 10.9526\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.9297 - mae: 10.9297\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.9065 - mae: 10.9065\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.8831 - mae: 10.8831\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8594 - mae: 10.8594\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.8355 - mae: 10.8355\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8113 - mae: 10.8113\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.7869 - mae: 10.7869\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.7624 - mae: 10.7624\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.7378 - mae: 10.7378\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f213f17f590>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN7Fl8fmW2Q5",
        "outputId": "41cfd4eb-46a1-44fa-c06c-08f941f4268b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.1423874]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy is lower than all above models"
      ],
      "metadata": {
        "id": "9WW6EnQ9W7uT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(50, activation=None, input_shape=[1]),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt6TREmPXBUY",
        "outputId": "de7d926c-dc00-4da8-d7f4-954fcd6941bd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 341ms/step - loss: 12.9604 - mae: 12.9604\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.2709 - mae: 12.2709\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.5734 - mae: 11.5734\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.8663 - mae: 10.8663\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 10.1473 - mae: 10.1473\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4136 - mae: 9.4136\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6625 - mae: 8.6625\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.8916 - mae: 7.8916\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0987 - mae: 7.0987\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8039 - mae: 6.8039\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4792 - mae: 7.4792\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7321 - mae: 7.7321\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7397 - mae: 7.7397\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5648 - mae: 7.5648\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2529 - mae: 7.2529\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9511 - mae: 6.9511\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6721 - mae: 6.6721\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3800 - mae: 6.3800\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1911 - mae: 6.1911\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1471 - mae: 6.1471\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2265 - mae: 6.2265\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3130 - mae: 6.3130\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2968 - mae: 6.2968\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1905 - mae: 6.1905\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0035 - mae: 6.0035\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7425 - mae: 5.7425\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6089 - mae: 5.6089\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5017 - mae: 5.5017\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4947 - mae: 5.4947\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5075 - mae: 5.5075\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4749 - mae: 5.4749\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4004 - mae: 5.4004\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2877 - mae: 5.2877\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1401 - mae: 5.1401\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9611 - mae: 4.9611\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7535 - mae: 4.7535\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6692 - mae: 4.6692\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5830 - mae: 4.5830\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5806 - mae: 4.5806\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5130 - mae: 4.5130\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3328 - mae: 4.3328\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1027 - mae: 4.1027\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9511 - mae: 3.9511\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7932 - mae: 3.7932\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7466 - mae: 3.7466\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6534 - mae: 3.6534\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5097 - mae: 3.5097\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3182 - mae: 3.3182\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0817 - mae: 3.0817\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8599 - mae: 2.8599\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6992 - mae: 2.6992\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6236 - mae: 2.6236\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4239 - mae: 2.4239\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1108 - mae: 2.1108\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8815 - mae: 1.8815\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7573 - mae: 1.7573\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5715 - mae: 1.5715\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3208 - mae: 1.3208\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9668 - mae: 0.9668\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8875 - mae: 0.8875\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7324 - mae: 0.7324\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3997 - mae: 0.3997\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0974 - mae: 0.0974\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3419 - mae: 0.3419\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4940 - mae: 0.4940\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6072 - mae: 0.6072\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6224 - mae: 0.6224\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6441 - mae: 0.6441\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6450 - mae: 0.6450\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5953 - mae: 0.5953\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5428 - mae: 0.5428\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3803 - mae: 0.3803\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2506 - mae: 0.2506\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1543 - mae: 0.1543\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1186 - mae: 0.1186\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2001 - mae: 0.2001\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2367 - mae: 0.2367\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3064 - mae: 0.3064\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2927 - mae: 0.2927\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2667 - mae: 0.2667\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2087 - mae: 0.2087\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1350 - mae: 0.1350\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0479 - mae: 0.0479\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2258 - mae: 0.2258\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1876 - mae: 0.1876\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3738 - mae: 0.3738\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4405 - mae: 0.4405\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3273 - mae: 0.3273\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2315 - mae: 0.2315\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2016 - mae: 0.2016\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1211 - mae: 0.1211\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0758 - mae: 0.0758\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2930 - mae: 0.2930\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3346 - mae: 0.3346\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1785 - mae: 0.1785\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3471 - mae: 0.3471\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3985 - mae: 0.3985\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1476 - mae: 0.1476\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3660 - mae: 0.3660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2136e34a10>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRC4oRKtcyd9",
        "outputId": "5d936cc6-cd1f-4323-e869-31d6c0b2c1e8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6xn873Wcy5R",
        "outputId": "63a462e6-b4d9-41f1-cb3b-815d4f556cf6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[25.587885]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common ways to improve a deep model**\n",
        "* Adding layers\n",
        "* Increase the number of hidden units\n",
        "* Change the activation functions\n",
        "* Change the optimization function\n",
        "* Change the learning rate ***lr or learning_rate***\n",
        "* Fitting on more data\n",
        "* Fit for longer ***epochs***"
      ],
      "metadata": {
        "id": "aD13H8aZeMuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a model\n",
        "\n",
        "In practise, a typical workflow to go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it...\n",
        "```"
      ],
      "metadata": {
        "id": "nLnJdNJXdHrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to evaluation:\n",
        "> Visualize, Visualize, Visualize\n",
        "\n",
        "It's a good idea to visualize: \n",
        "* The data - what data are we working with? What does it look like?\n",
        "* The midel itself - what does our model look like?\n",
        "* The training of a model - how does a model perform while it learns?\n",
        "* The predictions of the model - how does the predictions of the model line up with the actual results (ground truth)?"
      ],
      "metadata": {
        "id": "pYsCBXB1djYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N2G1pp4gBaP",
        "outputId": "5497f649-33e7-492a-8936-9a961ba2e66f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foeqsukpgZBO",
        "outputId": "a80d1dfa-b52c-404b-d7b5-7eef8d5b84e1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ox_e4VDekuPF",
        "outputId": "c6067aab-d205-4957-a9bb-c3a07c229fa7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f213692b850>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The 3 sets...\n",
        "\n",
        "* **Training set** - the model learns from this data, which is typically 70% - 80% of total data\n",
        "* **Validation set** - the model gets tuned on this data which is typically 10% - 15% of data available\n",
        "* **Test set** - the model gets evaluated on this data to test what it has learned, this set is typically 10% - 15% of the total data available"
      ],
      "metadata": {
        "id": "ZKdhj5iLk4vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of how many sampes we have\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAyJ9O4mlecx",
        "outputId": "cf05ce0e-c7d5-4a57-d401-e9a998fe81e7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train = X[:40] # first 40 training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 testing samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn9tSRNLmIkd",
        "outputId": "ba2dc5e5-bd55-4efb-85e3-18bf4e4abc1e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qy_eSBeSms49"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}